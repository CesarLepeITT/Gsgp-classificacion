# GSGP-CUDA (Geometric Semantic Genetic Programming with CUDA)

*GSGP-CUDA* is an innovative software tool that leverages the power of Genetic Programming (GP) for symbolic regression tasks. This advanced framework incorporates geometric semantic operators and is optimized for high-performance computing through CUDA (Compute Unified Device Architecture). It enables the exploration and discovery of mathematical expressions and models within complex datasets. With GSGP-CUDA, you can efficiently evolve solutions, perform semantic analysis, and visualize the semantic landscape of your problems. This versatile tool offers a range of configurations and settings, making it suitable for various real-world regression challenges. Harness the potential of GSGP-CUDA for symbolic regression, data modeling, and more.

```
This is a C/C++/CUDA implementation of a geometric semantic genetic programming algorithm with a python/sklearn interface.
```

## How does it work?
GSGP-CUDA, or Geometric Semantic Genetic Programming with CUDA, operates through a process similar to genetic programming (GP). In this framework, a population of mathematical expressions and symbolic models is evolved over multiple generations.

## Build instructions
We have provided a conda environment, configuration script and installation script that should make installation straightforward. We've currently tested this on Ubuntu. Steps:

Toolkit CUDA v10.1 && v9.2, GCC v7.4.0, CUBLAS v2.0, Linux Headers, unix-like systems, Ubuntu Linux18.04
The use of a virtual environment (Conda) is recommended.
python 3.8
scikit-learn 1.0.2
numpy 1.21.5
pandas 1.4.2

1. Install the conda environment

```
conda env create -f environment.yml
conda activate gsgpcuda
```
# Using GSGP-CUDA


# How to run GSGP-CUDA using the Scikitlearn API in Python

```
#import library
import gsgpcuda as gsgp

#instantiate the object
est = gsgpcuda.gsgpcudaregressor(
        g=200,
        pop_size=1024,
        max_len=1024,
        func_ratio=0.5,
        variable_ratio=0.5,
        max_rand_constant=10,
        sigmoid = 1,
        error_function=0,
        oms=1,
        normalize=1,
        do_min_max=2,
        protected_division=0
    )

#train model
est.fit(X_train,y_train)

#prediction model
values_predict = est.predict(X_test)



```

# How to run GSGP-CUDA in command line
How to compile.

```
nvcc -std=c++11 -O0 GsgpCuda.cu -o GsgpCuda.x  -lcublas
```

To run gsgpCuda it is necessary to add a name for the output file generation, as shown in the example.

```
./GsgpCuda.x -train_data <train_file_name>.txt -test_data <test_file_name>.txt -output_model <model_name>

<train_file_name>.txt: This file must contain the training data used to compute fitness and given in a format of space-seperated values with n columns, where the first n-1 columns are the input features and the last column is the target variable.

<test_file_name>.txt:  This file must contain the test data used to evalaute the best individual at each generation. this data does not influence the evolutionary/training process, and must be given in the same format as the training data.

If no test data is available, the user can indicate the same file as the training data to assure proper excecution, this does not afffect model evolution.

<model_name>.csv: This file contains the information needed to apply the best model found by gsgpcuda on new data (make new predictions or inferences). other auxiliary files are also generated and required.
```

GsgpCuda generates the following output files, which are located in the log folder:

```
<model_name>_initialPopulation.csv: This file will store the individuals of the initial population.

<model_name>_randomTrees.csv: This file will store the individuals of the auxiliary population.

<model_name>_fitnessTrain.csv: This file will store the error of the best individual in each generation with training data.

<model_name>_fitnessTest.csv: This file will store the error of the best individual in each generation with test data.

<model_name>_processing_time.csv: This file stores the processing times in seconds of the various modules of the algorithm. 
```

To make new predictions with the best model generated by gsgpcuda it is necessary to provide the name of the model by command line, the second parameter indicates the name of the data file, and the third parameter indicates the name of the file to save the output values generated by the model.

```
./GsgpCuda.x -model <model_name> -input_data <new_data>.txt -prediction_output <predicted_values>.csv

<model_name>: this file contains the information needed to test the model generated by gsgpcuda.

<new_data>.txt: this file must contain the new unseen data for testing the model. the file should have the same number of columns as the number of input features in the train.txt file used to train the data, without the target column.

<predicted_values>.csv: this file will store the output values generated by the model when tested on the data in newdata.txt.
```

## Hyperparameters

You can specify hyperparameter values to the class constructor to configure the model.

| Name     								| Values   | Description|
| -------- 								| -------- |------------|
|1.  Number of generations				| 1024     |Total number of iterations of the main evolutionary loop. |
|2.  Population Size					| 1024     |Number of individuals in the population; also specifies the number of auxiliary random trees used in GSGP mutation operation.|
|3.  Max Individual Length      		| 1024     |Size (number of genes) of each individual in the population and the auxiliary population.|
|4.  FunctionRatio                      | 0.5      |Probability of selecting a function, otherwise a terminal element is selected when generating an individual.|
|5.  VariableRatio                      | 0.5      |Probability of selecting a variable, otherwise a constant terminal is selected when generating an individual.|
|6.  Maximun Random Constant			| 10       |Maximum value of the random constants used. Whatever the value, negative constants of the same magnitude are also generated.|
|7.  Act_function                       | 0, 1, 2  |Choice of activation function: '0' Scaled Sigmoidal Activation Function; ‘1’ Sigmoidal Activation Function; ‘2’ Hyperbolic Tangent Activation Function|
|8. Error_function | 0, 1 | Choice of fitness function: '0' Root-Mean-Squared-Error (RMSE); ‘1’ Coefficient of determination (R2).|
|9.  oms                                | 0, 1     |Type of mutation step: '0' GSM with a random mutation step for each mutation event; ‘1’ Optimal Mutation Step (OMS)|
|10.  Normalize                         | 0, 1     |GSM Normalization:  '0' Standard GSM mutation, with the difference of two random programs and activation function; ‘1’ Using normalized or standardized versions of GSM with one random tree and activation functions are ignored.|
|11.  do_min_max                        | 0, 1, 2  |Type of normalized GSM variant used. The hyperparameter is ignored if Normalize=’0’, options are: '0' Standarization of the single random tree used in GSM; ‘1’ Min-Max normalization for the single random program used in GSM; ‘2’ combined approach, first standardization followed by Min-Max Normalzation.|
|10.  Protected_division                | 0, 1     |The variable "Protected_division" allows the selection of the division mode applied. The available options are: 0: Selection of the division operator used: ‘0’ Standard Protected Division; ‘1’ Analytic Quotient Operator|


# Data Description
It is important that the problem data are not separated by ",". Please separate your data by a blank space " ".

# Test kernels
How to compile for kernel unit tests that initialize the population.

```
nvcc -std=c++11 -O0 testInitialPopulation.cu -o testInitialPopulation.x
```

How to run.

```
./testInitialPopulation.x
```
How to compile for kernel unit tests that calculate the semantics.

```
nvcc -std=c++11 -O0 testSemantic.cu -o testSemantic.x 
```

How to run.

```
./testSemantic.x 
```

How to compile for kernel unit tests that executes the semantic geometric mutation operator.

```
nvcc -std=c++11 -O0 gsmTest.cu -o gsmTest.x
```

How to run.

```
./gsmTest.x
```

# Documentation
The documentation of the library is a Doxygen documentation. The implementation has been done in order to use the library after a very quick reading of the documentation.

# References
```
Implementation of GSGP-CUDA
```
Leonardo Trujillo, Jose Manuel Muñoz Contreras, Daniel E.Hernandez, Mauro Castelli, Juan J.Tapia. GSGP-CUDA — A CUDA framework for Geometric Semantic Genetic Programming in SoftwareX, Volume 18, June 2022, 101085. [SoftwareX](https://www.sciencedirect.com/science/article/pii/S2352711022000607)

```
Normalized GSM Variants
```

Illya Bakurov, Jose Manuel Muñoz Contreras, Mauro Castelli, Nuno Rodrigues, Sara Silva, Leonardo Trujillo, Leonardo Vanneschi, “Geometric Semantic Genetic Programming with Normalized and Standardized Random Programs” Genetic Programming and Evolves Machine, 2023-accepted